{
   "feed":{
      "@xmlns":"http://www.w3.org/2005/Atom",
      "link":{
         "@href":"http://arxiv.org/api/query?search_query%3Dcat%3Acs.AI%26id_list%3D%26start%3D0%26max_results%3D2",
         "@rel":"self",
         "@type":"application/atom+xml"
      },
      "title":{
         "@type":"html",
         "#text":"ArXiv Query: search_query=cat:cs.AI&id_list=&start=0&max_results=2"
      },
      "id":"http://arxiv.org/api/sLG0txIUz7g/GKW7ibPhDY0NNSQ",
      "updated":"2023-05-16T00:00:00-04:00",
      "opensearch:totalResults":{
         "@xmlns:opensearch":"http://a9.com/-/spec/opensearch/1.1/",
         "#text":"62895"
      },
      "opensearch:startIndex":{
         "@xmlns:opensearch":"http://a9.com/-/spec/opensearch/1.1/",
         "#text":"0"
      },
      "opensearch:itemsPerPage":{
         "@xmlns:opensearch":"http://a9.com/-/spec/opensearch/1.1/",
         "#text":"2"
      },
      "entry":[
         {
            "id":"http://arxiv.org/abs/2305.08854v1",
            "updated":"2023-05-15T17:59:57Z",
            "published":"2023-05-15T17:59:57Z",
            "title":"Laughing Matters: Introducing Laughing-Face Generation using Diffusion\n  Models",
            "summary":"Speech-driven animation has gained significant traction in recent years, with\ncurrent methods achieving near-photorealistic results. However, the field\nremains underexplored regarding non-verbal communication despite evidence\ndemonstrating its importance in human interaction. In particular, generating\nlaughter sequences presents a unique challenge due to the intricacy and nuances\nof this behaviour. This paper aims to bridge this gap by proposing a novel\nmodel capable of generating realistic laughter sequences, given a still\nportrait and an audio clip containing laughter. We highlight the failure cases\nof traditional facial animation methods and leverage recent advances in\ndiffusion models to produce convincing laughter videos. We train our model on a\ndiverse set of laughter datasets and introduce an evaluation metric\nspecifically designed for laughter. When compared with previous speech-driven\napproaches, our model achieves state-of-the-art performance across all metrics,\neven when these are re-trained for laughter generation.",
            "author":[
               {
                  "name":"Antoni Bigata Casademunt"
               },
               {
                  "name":"Rodrigo Mira"
               },
               {
                  "name":"Nikita Drobyshev"
               },
               {
                  "name":"Konstantinos Vougioukas"
               },
               {
                  "name":"Stavros Petridis"
               },
               {
                  "name":"Maja Pantic"
               }
            ],
            "link":[
               {
                  "@href":"http://arxiv.org/abs/2305.08854v1",
                  "@rel":"alternate",
                  "@type":"text/html"
               },
               {
                  "@title":"pdf",
                  "@href":"http://arxiv.org/pdf/2305.08854v1",
                  "@rel":"related",
                  "@type":"application/pdf"
               }
            ],
            "arxiv:primary_category":{
               "@xmlns:arxiv":"http://arxiv.org/schemas/atom",
               "@term":"cs.CV",
               "@scheme":"http://arxiv.org/schemas/atom"
            },
            "category":[
               {
                  "@term":"cs.CV",
                  "@scheme":"http://arxiv.org/schemas/atom"
               },
               {
                  "@term":"cs.AI",
                  "@scheme":"http://arxiv.org/schemas/atom"
               },
               {
                  "@term":"cs.LG",
                  "@scheme":"http://arxiv.org/schemas/atom"
               }
            ]
         },
         {
            "id":"http://arxiv.org/abs/2305.08852v1",
            "updated":"2023-05-15T17:59:34Z",
            "published":"2023-05-15T17:59:34Z",
            "title":"Python Tool for Visualizing Variability of Pareto Fronts over Multiple\n  Runs",
            "summary":"Hyperparameter optimization is crucial to achieving high performance in deep\nlearning. On top of the performance, other criteria such as inference time or\nmemory requirement often need to be optimized due to some practical reasons.\nThis motivates research on multi-objective optimization (MOO). However, Pareto\nfronts of MOO methods are often shown without considering the variability\ncaused by random seeds and this makes the performance stability evaluation\ndifficult. Although there is a concept named empirical attainment surface to\nenable the visualization with uncertainty over multiple runs, there is no major\nPython package for empirical attainment surface. We, therefore, develop a\nPython package for this purpose and describe the usage. The package is\navailable at https://github.com/nabenabe0928/empirical-attainment-func.",
            "author":{
               "name":"Shuhei Watanabe"
            },
            "arxiv:comment":{
               "@xmlns:arxiv":"http://arxiv.org/schemas/atom",
               "#text":"Submitted to AutoML workshop"
            },
            "link":[
               {
                  "@href":"http://arxiv.org/abs/2305.08852v1",
                  "@rel":"alternate",
                  "@type":"text/html"
               },
               {
                  "@title":"pdf",
                  "@href":"http://arxiv.org/pdf/2305.08852v1",
                  "@rel":"related",
                  "@type":"application/pdf"
               }
            ],
            "arxiv:primary_category":{
               "@xmlns:arxiv":"http://arxiv.org/schemas/atom",
               "@term":"cs.AI",
               "@scheme":"http://arxiv.org/schemas/atom"
            },
            "category":[
               {
                  "@term":"cs.AI",
                  "@scheme":"http://arxiv.org/schemas/atom"
               },
               {
                  "@term":"cs.LG",
                  "@scheme":"http://arxiv.org/schemas/atom"
               }
            ]
         }
      ]
   }
}